{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "base_dir = \"../../scripts/segmentation/models/carla_parametric\"\n",
    "config_dir = os.path.join(base_dir, \"configs\")\n",
    "model_dir = os.path.join(base_dir, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from avstack.config import Config\n",
    "from fov.segmentation.dataset import BinaryFovDataset\n",
    "from fov.segmentation.utils import get_unet_model\n",
    "\n",
    "\n",
    "class ToDevice:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, image: torch.Tensor):\n",
    "        return image.to(self.device)\n",
    "\n",
    "\n",
    "def get_model_dataset(width: int, depth: int, resol: int, device=\"cpu\"):\n",
    "    # specify the cfg to use\n",
    "    cfg_name = f\"width_{width}_depth_{depth}_resolution_{resol}\"\n",
    "    cfg_file = os.path.join(\n",
    "        config_dir, cfg_name + \".py\"\n",
    "    )\n",
    "    cfg = Config.fromfile(cfg_file)\n",
    "\n",
    "\n",
    "    # set up the transforms\n",
    "    trans = transforms.Compose([\n",
    "        ToDevice(device=device),\n",
    "        transforms.Resize(size=cfg[\"model_io_size\"]),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # load the dataset\n",
    "    split = \"val\"\n",
    "    seg_dataset = BinaryFovDataset(\n",
    "        cfg[\"data_output_dir\"],\n",
    "        transform=trans,\n",
    "        transform_mask=trans,\n",
    "        split=split,\n",
    "        max_range=cfg[\"max_range\"],\n",
    "        extent=cfg[\"extent\"],\n",
    "        img_size=cfg[\"img_size\"],\n",
    "    )\n",
    "\n",
    "    # load a trained model\n",
    "    model = get_unet_model(\n",
    "        cfg=cfg,\n",
    "        weight_dir=os.path.join(model_dir, cfg_name),\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return model, seg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "def fill_holes(image: np.ndarray):\n",
    "    \"\"\"Fills holes in a binary image.\"\"\"\n",
    "    # Threshold the image to ensure it's binary (if needed)\n",
    "    # _, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Copy the thresholded image\n",
    "    im_floodfill = image.copy()\n",
    "\n",
    "    # Mask used for flood fill.\n",
    "    # Size needs to be 2 pixels larger than the image\n",
    "    h, w = image.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    # Flood fill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
    "\n",
    "    # Invert flood filled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "\n",
    "    # Combine the two images to get the filled holes\n",
    "    im_out = image | im_floodfill_inv\n",
    "\n",
    "    return im_out\n",
    "\n",
    "\n",
    "def show_results(idx, model, seg_dataset, save_prefix):\n",
    "    # set colormaps\n",
    "    plt.set_cmap(\"Greys\")\n",
    "    cmap_base = colors.LinearSegmentedColormap.from_list(\"wt\", [\"white\", \"teal\"])\n",
    "    cmap_overlay = colors.LinearSegmentedColormap.from_list(\n",
    "        \"wtb\", [\"white\", \"teal\", \"darkslategrey\"]\n",
    "    )\n",
    "\n",
    "    # show some examples\n",
    "    image, mask = seg_dataset[idx]\n",
    "\n",
    "    # -- input image\n",
    "    print(image.shape, mask.shape)\n",
    "    plt.imshow(image[0, ...] > 0, cmap=cmap_base)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(save_prefix + \"input_image.png\")\n",
    "    plt.savefig(save_prefix + \"input_image.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # -- ground truth mask\n",
    "    plt.imshow(mask[0, :, :], cmap=cmap_base)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(save_prefix + \"gt_mask.png\")\n",
    "    plt.savefig(save_prefix + \"gt_mask.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # -- inference, probs\n",
    "    res = model(pc_img=image[None, ...], pc_np=None, metadata=None).detach().numpy()\n",
    "    plt.imshow(res[0, 0, ...], cmap=cmap_base)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(save_prefix + \"inference_probs.png\")\n",
    "    plt.savefig(save_prefix + \"inference_probs.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # -- inference, binary\n",
    "    threshold = 0.7\n",
    "    plt.imshow(fill_holes((res[0, 0, ...] > threshold).astype(np.uint8)), cmap=cmap_base)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(save_prefix + \"inference_bin.png\")\n",
    "    plt.savefig(save_prefix + \"inference_bin.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up paths for saving\n",
    "fig_dir = \"figures/parametric/case\"\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots over resolution\n",
    "idx_frame = 0\n",
    "width = 8\n",
    "depth = 4\n",
    "device = \"cpu\"\n",
    "for resol in [64, 128, 256, 512]:\n",
    "    save_prefix = os.path.join(fig_dir, f\"parametric_resol_{resol}_\")\n",
    "    model, dataset = get_model_dataset(width, depth, resol, device)\n",
    "    show_results(idx_frame, model, dataset, save_prefix=save_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fov-security-pWvESQ_k-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
