{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the metrics on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# set up configs and weights\n",
    "model_cfgs =  {\n",
    "    \"CARLA\": {\n",
    "        \"model\": \"../../config/segmentation/carla/unet_carla_benign.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/carla/unet_carla_benign\",\n",
    "    },\n",
    "    \"nuScenes\": {\n",
    "        \"model\": \"../../config/segmentation/nuscenes/unet_nuscenes_benign.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/nuscenes/unet_nuscenes_benign\",\n",
    "    },\n",
    "    \"UGV\": {\n",
    "        \"model\": \"../../config/segmentation/ugv/unet_ugv_benign.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/ugv/unet_ugv_benign\",\n",
    "    },\n",
    "    \"CARLA_mc\": {\n",
    "        \"model\": \"../../config/segmentation/carla/unet_carla_benign_mc.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/carla/unet_carla_benign_mc\",\n",
    "    },\n",
    "    \"nuScenes_mc\": {\n",
    "        \"model\": \"../../config/segmentation/nuscenes/unet_nuscenes_benign_mc.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/nuscenes/unet_nuscenes_benign_mc\",\n",
    "    },\n",
    "    \"UGV_mc\": {\n",
    "        \"model\": \"../../config/segmentation/ugv/unet_ugv_benign_mc.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/ugv/unet_ugv_benign_mc\",\n",
    "    },\n",
    "    \"CARLA_adv\": {\n",
    "        \"model\": \"../../config/segmentation/carla/unet_carla_adversarial.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/carla/unet_carla_adversarial\",\n",
    "    },\n",
    "    \"nuScenes_adv\": {\n",
    "        \"model\":\"../../config/segmentation/nuscenes/unet_nuscenes_adversarial.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/nuscenes/unet_nuscenes_adversarial\",\n",
    "    },\n",
    "    \"UGV_adv\": {\n",
    "        \"model\": \"../../config/segmentation/ugv/unet_ugv_adversarial.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/ugv/unet_ugv_adversarial\",\n",
    "    },\n",
    "    \"CARLA_adv_mc\": {\n",
    "        \"model\": \"../../config/segmentation/carla/unet_carla_adversarial_mc.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/carla/unet_carla_adversarial_mc\",\n",
    "    },\n",
    "    \"nuScenes_adv_mc\": {\n",
    "        \"model\": \"../../config/segmentation/nuscenes/unet_nuscenes_adversarial_mc.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/nuscenes/unet_nuscenes_adversarial_mc\",\n",
    "    },\n",
    "    \"UGV_adv_mc\": {\n",
    "        \"model\": \"../../config/segmentation/ugv/unet_ugv_adversarial_mc.py\",\n",
    "        \"weights\": \"../../scripts/segmentation/models/ugv/unet_ugv_adversarial_mc\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# set up datasets\n",
    "dataset_cfgs = {\n",
    "    \"CARLA\": \"../../config/segmentation/__base__/datasets/carla.py\",\n",
    "    \"nuScenes\": \"../../config/segmentation/__base__/datasets/nuscenes.py\",\n",
    "    \"UGV\": \"../../config/segmentation/__base__/datasets/ugv.py\",\n",
    "    \"CARLA_adv\": \"../../config/segmentation/__base__/datasets/carla_adversarial.py\",\n",
    "    \"nuScenes_adv\": \"../../config/segmentation/__base__/datasets/nuscenes_adversarial.py\",\n",
    "    \"UGV_adv\": \"../../config/segmentation/__base__/datasets/ugv_adversarial.py\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avstack.config import Config\n",
    "from fov.segmentation.utils import get_dataset, get_unet_model\n",
    "\n",
    "\n",
    "# preload all the models\n",
    "models = {\n",
    "    m_name: get_unet_model(\n",
    "        cfg=Config.fromfile(model_cfgs[m_name][\"model\"]),\n",
    "        device=device,\n",
    "        weight_dir=model_cfgs[m_name][\"weights\"],\n",
    "    )\n",
    "    for m_name in model_cfgs.keys()\n",
    "}\n",
    "\n",
    "\n",
    "# preload all the datasets (SM, dataset)\n",
    "datasets = {\n",
    "    d_name: get_dataset(\n",
    "        cfg=Config.fromfile(dataset_cfgs[d_name]),\n",
    "        device=device,\n",
    "        split=\"val\",\n",
    "    )\n",
    "    for d_name in dataset_cfgs.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "from eval_utils import test_model_on_dataset\n",
    "\n",
    "\n",
    "# preset the dataset dictionary\n",
    "all_results = defaultdict(dict)\n",
    "\n",
    "# parameters for evaluation\n",
    "n_frames_max = 200\n",
    "\n",
    "# run cross-wise evaluations\n",
    "for name_model_dataset in model_cfgs.keys():\n",
    "    # load in the model\n",
    "    model = models[name_model_dataset]\n",
    "\n",
    "    # get the dataset to evaluate on\n",
    "    for name_test_dataset in dataset_cfgs.keys():\n",
    "\n",
    "        # load in the dataset\n",
    "        SM, seg_dataset = datasets[name_test_dataset]\n",
    "\n",
    "        # run the evaluation\n",
    "        results = test_model_on_dataset(\n",
    "            model=model,\n",
    "            name_model_dataset=name_model_dataset,\n",
    "            seg_dataset=seg_dataset,\n",
    "            name_test_dataset=name_test_dataset,\n",
    "            n_frames_max=n_frames_max,\n",
    "        )\n",
    "\n",
    "        # store results\n",
    "        all_results[name_model_dataset][name_test_dataset] = results\n",
    "\n",
    "# save results\n",
    "with open(\"model_train_test.p\", \"wb\") as f:\n",
    "    pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some results figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# set up paths for saving\n",
    "fig_dir = \"figures/train_test\"\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fill_holes(image: np.ndarray):\n",
    "    \"\"\"Fills holes in a binary image.\"\"\"\n",
    "    # Threshold the image to ensure it's binary (if needed)\n",
    "    # _, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Copy the thresholded image\n",
    "    im_floodfill = image.copy()\n",
    "\n",
    "    # Mask used for flood fill.\n",
    "    # Size needs to be 2 pixels larger than the image\n",
    "    h, w = image.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    # Flood fill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
    "\n",
    "    # Invert flood filled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "\n",
    "    # Combine the two images to get the filled holes\n",
    "    im_out = image | im_floodfill_inv\n",
    "\n",
    "    return im_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from avapi.visualize.snapshot import show_lidar_bev_with_boxes\n",
    "\n",
    "from fov.segmentation.utils import get_polygon_model\n",
    "from eval_utils import get_metrics\n",
    "\n",
    "# set colormaps\n",
    "plt.set_cmap(\"Greys\")\n",
    "cmap_base = colors.LinearSegmentedColormap.from_list(\"wt\", [\"white\", \"teal\"])\n",
    "cmap_overlay = colors.LinearSegmentedColormap.from_list(\n",
    "    \"wtb\", [\"white\", \"teal\", \"darkslategrey\"]\n",
    ")\n",
    "\n",
    "# set up the frames to evaluate\n",
    "idx_frame_eval = {\"CARLA\": 10, \"nuScenes\": 5, \"UGV\": 3, \"CARLA_adv\": 10, \"nuScenes_adv\": 6}\n",
    "\n",
    "# loop over model/dataset pairs\n",
    "for name_model_dataset in model_cfgs.keys():\n",
    "    # load in the model\n",
    "    model = models[name_model_dataset]\n",
    "\n",
    "    # get the dataset to evaluate on\n",
    "    for name_test_dataset in dataset_cfgs.keys():\n",
    "        results = defaultdict(list)  # set the results for this combo\n",
    "\n",
    "        # load in the dataset\n",
    "        SM, seg_dataset = datasets[name_test_dataset]\n",
    "\n",
    "        # run the evaluation\n",
    "        print(\n",
    "            f\"\\n----Evaluating model from {name_model_dataset.upper()} \"\n",
    "            f\"on {name_test_dataset.upper()} data\"\n",
    "        )\n",
    "\n",
    "        # get data\n",
    "        frame = idx_frame_eval[name_test_dataset]\n",
    "        pc_img, gt_mask = seg_dataset[frame]\n",
    "        pc_img = torch.unsqueeze(pc_img, 0)\n",
    "        pc_np = seg_dataset.get_pointcloud(frame)\n",
    "        pc_avstack = seg_dataset.get_pointcloud_avstack(frame, SM)\n",
    "        gt_poly_avstack = seg_dataset.get_polygon_avstack(frame, SM)\n",
    "        metadata = seg_dataset.get_metadata(frame)\n",
    "\n",
    "        # inference\n",
    "        img_pred = model(pc_img, pc_np, metadata)\n",
    "\n",
    "        # metrics\n",
    "        this_results = get_metrics(img_pred, gt_mask, metadata)\n",
    "\n",
    "        ###############################\n",
    "        # visualizations\n",
    "        ###############################\n",
    "        \n",
    "        # get polygon model for postproc\n",
    "        poly_model = get_polygon_model(model=\"fast_ray_trace\", extent=seg_dataset._extent, device=\"cpu\")\n",
    "\n",
    "        # set up directories\n",
    "        fig_dir_this = os.path.join(\n",
    "            fig_dir, f\"model_{name_model_dataset}_dataset_{name_test_dataset}\"\n",
    "        )\n",
    "        os.makedirs(fig_dir_this, exist_ok=True)\n",
    "        fig_file_base = os.path.join(\n",
    "            fig_dir_this,\n",
    "            f\"model_{name_model_dataset}_dataset_{name_test_dataset}_frame_{frame}_{{}}\",\n",
    "        )\n",
    "\n",
    "        # avstack pc image\n",
    "        pc_img_avstack = show_lidar_bev_with_boxes(\n",
    "            pc=pc_avstack,\n",
    "            boxes=[],\n",
    "            return_image=True,\n",
    "            show=True,\n",
    "            scale_return_image=True,\n",
    "        )\n",
    "        cv2.imwrite(\n",
    "            fig_file_base.format(\"pc_img_in_avstack.png\"),\n",
    "            cv2.cvtColor(pc_img_avstack, cv2.COLOR_BGR2RGB),\n",
    "        )\n",
    "\n",
    "        # avstack pc image with fov (convert fov image to polygon)\n",
    "        pc_img_avstack_fov = show_lidar_bev_with_boxes(\n",
    "            pc=pc_avstack,\n",
    "            boxes=[],\n",
    "            background_color=\"black\",\n",
    "            fov=gt_poly_avstack,\n",
    "            fov_filled=True,\n",
    "            fov_filled_alpha=0.5,\n",
    "            return_image=True,\n",
    "            show=True,\n",
    "            scale_return_image=True,\n",
    "        )\n",
    "        cv2.imwrite(\n",
    "            fig_file_base.format(\"pc_img_in_with_fov_avstack.png\"),\n",
    "            cv2.cvtColor(pc_img_avstack_fov, cv2.COLOR_BGR2RGB),\n",
    "        )\n",
    "\n",
    "        # pc image\n",
    "        pc_img_np = pc_img.detach().cpu().numpy()[0, 0, ...]\n",
    "        plt.imshow(pc_img_np, cmap=cmap_base)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(fig_file_base.format(\"pc_img_in.png\"))\n",
    "        plt.savefig(fig_file_base.format(\"pc_img_in.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # binarized pc image\n",
    "        plt.imshow(pc_img_np > 0, cmap=cmap_overlay)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(fig_file_base.format(\"mask_img_in.png\"))\n",
    "        plt.savefig(fig_file_base.format(\"mask_img_in.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # ground truth mask\n",
    "        gt_mask_np = gt_mask.detach().cpu().numpy()[0, ...]\n",
    "        plt.imshow(gt_mask_np, cmap=cmap_base)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(fig_file_base.format(\"gt_mask.png\"))\n",
    "        plt.savefig(fig_file_base.format(\"gt_mask.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # predicted image\n",
    "        img_pred_np = img_pred.detach().cpu().numpy()[0, 0, ...]\n",
    "        plt.imshow(img_pred_np, cmap=cmap_base)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(fig_file_base.format(\"img_pred.png\"))\n",
    "        plt.savefig(fig_file_base.format(\"img_pred.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # predicted image binarized\n",
    "        threshold = 0.7\n",
    "        plt.imshow(img_pred_np > threshold, cmap=cmap_base)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(fig_file_base.format(\"mask_pred.png\"))\n",
    "        plt.savefig(fig_file_base.format(\"mask_pred.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # predicted image closed binarized\n",
    "        closed_image_bin = fill_holes((img_pred_np > threshold).astype(np.uint8))\n",
    "        plt.imshow(closed_image_bin > threshold, cmap=cmap_base)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(fig_file_base.format(\"mask_pred_closed.png\"))\n",
    "        plt.savefig(fig_file_base.format(\"mask_pred_closed.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # overlay points on closed binarized image\n",
    "        img_pred_overlay = closed_image_bin.astype(bool) + 2 * (pc_img_np > 0)\n",
    "        plt.imshow(np.minimum(2, img_pred_overlay), cmap=cmap_overlay)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(fig_file_base.format(\"mask_pred_overlay.png\"))\n",
    "        plt.savefig(fig_file_base.format(\"mask_pred_overlay.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # fit a polygon over it to use for AVstack image\n",
    "        pts_avstack = seg_dataset.img_to_pts_avstack(img_pred_np, metadata, SM, threshold=0.7)\n",
    "        poly_pred = poly_model.model(pts_avstack)\n",
    "        pc_img_pred_avstack_fov = show_lidar_bev_with_boxes(\n",
    "            pc=pc_avstack,\n",
    "            boxes=[],\n",
    "            background_color=\"black\",\n",
    "            fov=poly_pred,\n",
    "            fov_filled=True,\n",
    "            fov_filled_alpha=0.5,\n",
    "            return_image=True,\n",
    "            show=True,\n",
    "            scale_return_image=True,\n",
    "        )\n",
    "        cv2.imwrite(\n",
    "            fig_file_base.format(\"mask_pred_overlay_avstack.png\"),\n",
    "            cv2.cvtColor(pc_img_avstack_fov, cv2.COLOR_BGR2RGB),\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fov-security-pWvESQ_k-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
