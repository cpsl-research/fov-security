{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the parametric study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "base_dir = \"../../scripts/segmentation/models/carla_parametric\"\n",
    "config_dir = os.path.join(base_dir, \"configs\")\n",
    "model_dir = os.path.join(base_dir, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from avstack.config import Config\n",
    "from fov.segmentation.utils import get_dataset, get_unet_model\n",
    "\n",
    "\n",
    "# load up the models and datasets\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cfgs = []\n",
    "models = {}\n",
    "datasets = {}\n",
    "for fname in sorted(os.listdir(model_dir))[:-1]:  # the minus 1 is for while we're training\n",
    "    folder_path = os.path.join(model_dir, fname)\n",
    "    if os.path.isdir(folder_path):\n",
    "        cfg = Config.fromfile(os.path.join(config_dir, fname + \".py\"))\n",
    "\n",
    "        # model\n",
    "        model_cfgs.append(cfg)\n",
    "        models[fname] = get_unet_model(\n",
    "            cfg=cfg,\n",
    "            device=device,\n",
    "            weight_dir=os.path.join(model_dir, fname)\n",
    "        )\n",
    "\n",
    "        # dataset\n",
    "        datasets[fname] = get_dataset(\n",
    "            cfg=cfg,\n",
    "            device=device,\n",
    "            split=\"test\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from eval_utils import test_model_on_dataset_v2\n",
    "\n",
    "\n",
    "# preset the dataset dictionary\n",
    "all_results = []\n",
    "all_results_res = []\n",
    "n_frames_max = 200\n",
    "\n",
    "# get the 512x512 dataset\n",
    "dataset_512 = datasets[\"width_16_depth_3_resolution_512\"][1]\n",
    "\n",
    "# loop over models\n",
    "for model_name in models:\n",
    "    # pull out data structures\n",
    "    model = models[model_name]\n",
    "    SM, seg_dataset = datasets[model_name]\n",
    "\n",
    "    # set names\n",
    "    name_model_dataset = \"CARLA-\" + model_name\n",
    "    name_test_dataset = \"CARLA\"\n",
    "\n",
    "    # run the evaluation\n",
    "    results, results_res = test_model_on_dataset_v2(\n",
    "        model=model,\n",
    "        name_model_dataset=name_model_dataset,\n",
    "        seg_dataset=seg_dataset,\n",
    "        name_test_dataset=name_test_dataset,\n",
    "        n_frames_max=n_frames_max,\n",
    "        evaluate_at_resolution=True,\n",
    "        dataset_at_resolution=dataset_512,\n",
    "    )\n",
    "\n",
    "    # add model architecture parameters to results table\n",
    "    width, depth, resolution = [int(p) for p in model_name.split(\"_\")[1::2]]\n",
    "    for result in results:\n",
    "        result.update({\n",
    "            \"width\": width,\n",
    "            \"depth\": depth,\n",
    "            \"resolution\": resolution,\n",
    "            \"model_name\": model_name\n",
    "        })\n",
    "    for result in results_res:\n",
    "        result.update({\n",
    "            \"width\": width,\n",
    "            \"depth\": depth,\n",
    "            \"resolution\": resolution,\n",
    "            \"model_name\": model_name\n",
    "        })\n",
    "\n",
    "    # store results\n",
    "    all_results.extend(results)\n",
    "    all_results_res.extend(results_res)\n",
    "\n",
    "# save results\n",
    "with open(\"parametric_train_test.p\", \"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "with open(\"parametric_train_test_eval_at_res.p\", \"wb\") as f:\n",
    "    pickle.dump(all_results_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# load in the last saved results\n",
    "with open(\"parametric_train_test.p\", \"rb\") as f:\n",
    "    all_results = pickle.load(f)\n",
    "with open(\"parametric_train_test_eval_at_res.p\", \"rb\") as f:\n",
    "    all_results_res = pickle.load(f)\n",
    "    \n",
    "# expand results where entries are lists to each frame\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results_res = pd.DataFrame(all_results)\n",
    "\n",
    "# figure directory for saving\n",
    "fig_dir_metrics = \"figures/parametric/metrics\"\n",
    "os.makedirs(fig_dir_metrics, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "sns.color_palette(\"husl\", 8)\n",
    "\n",
    "hues = [\"depth\", \"resolution\"]\n",
    "\n",
    "# select which results we want to plot\n",
    "plot_eval_at_res = True\n",
    "if plot_eval_at_res:\n",
    "    df_plot = df_results_res\n",
    "else:\n",
    "    df_plot = df_results\n",
    "\n",
    "# make plots\n",
    "for hue in hues:\n",
    "    for metric in [\"precision\", \"recall\", \"accuracy\"]:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "        sns.barplot(\n",
    "            data=df_plot,\n",
    "            x=\"width\",\n",
    "            y=\"precision\",\n",
    "            hue=hue,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=3,\n",
    "            ax=ax,\n",
    "        )\n",
    "        plt.xlabel(\"Model Width\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.ylim([0, 1.0])\n",
    "        plt.title(f\"Segmentation {metric.capitalize()} on Test Set\")\n",
    "        plt.grid()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(fig_dir_metrics, f\"{metric}_by_width_and_{hue}.png\"))\n",
    "        plt.savefig(os.path.join(fig_dir_metrics, f\"{metric}_by_width_and_{hue}.pdf\"))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure directory for saving\n",
    "fig_dir_outputs = \"figures/parametric/outputs\"\n",
    "os.makedirs(fig_dir_outputs, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "# set colormaps\n",
    "plt.set_cmap(\"Greys\")\n",
    "cmap_base = colors.LinearSegmentedColormap.from_list(\"wt\", [\"white\", \"teal\"])\n",
    "cmap_overlay = colors.LinearSegmentedColormap.from_list(\n",
    "    \"wtb\", [\"white\", \"teal\", \"darkslategrey\"]\n",
    ")\n",
    "\n",
    "# get data\n",
    "i_frame = 100\n",
    "\n",
    "# set up the base figure file\n",
    "fig_file_base = os.path.join(\n",
    "    fig_dir_outputs,\n",
    "    f\"{{}}_frame_{i_frame}_{{}}\",\n",
    ")\n",
    "\n",
    "# show the ground truth on the 512x512\n",
    "print(\"Ground Truth Mask\")\n",
    "dataset_512 = datasets[\"width_16_depth_4_resolution_512\"][1]\n",
    "pc_img, gt_mask = dataset_512[i_frame]\n",
    "gt_mask_np = gt_mask.detach().cpu().numpy()[0, ...]\n",
    "plt.imshow(gt_mask_np, cmap=cmap_base)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(fig_file_base.format(\"gt\", \"mask.png\"))\n",
    "plt.savefig(fig_file_base.format(\"gt\", \"mask.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "# show the image input\n",
    "print(\"Image Input\")\n",
    "pc_img_np = pc_img.detach().cpu().numpy()[0, ...]\n",
    "plt.imshow(pc_img_np > 0, cmap=cmap_overlay)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(fig_file_base.format(\"input\", \"mask_img.png\"))\n",
    "plt.savefig(fig_file_base.format(\"input\", \"mask_img.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "# show model inferences\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    ds = datasets[model_name][1]\n",
    "    metadata = ds.get_metadata(i_frame)\n",
    "    pc_img, gt_mask = ds[i_frame]\n",
    "    pc_img = torch.unsqueeze(pc_img, 0)\n",
    "    pc_np = ds.get_pointcloud(i_frame)\n",
    "\n",
    "    # inference\n",
    "    img_pred = models[model_name](pc_img, pc_np, metadata)\n",
    "\n",
    "    # plotting\n",
    "    threshold = 0.7\n",
    "    img_pred_np = img_pred.detach().cpu().numpy()[0, 0, ...]\n",
    "    plt.imshow(img_pred_np > threshold, cmap=cmap_base)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(fig_file_base.format(model_name, \"mask_pred.png\"))\n",
    "    plt.savefig(fig_file_base.format(model_name, \"mask_pred.pdf\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fov-security-pWvESQ_k-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
